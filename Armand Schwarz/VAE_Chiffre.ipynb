{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as distrib\n",
    "import torchvision\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from torchvision import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=torchvision.transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 4     # Loading the dataset is using 4 CPU threads\n",
    "batch_size  = 128   # Using minibatches of 128 samples\n",
    "train_loader = torch.utils.data.DataLoader(dataset=mnist_trainset, batch_size=batch_size, num_workers=num_threads)\n",
    "#valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False, num_workers=num_threads)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=mnist_testset,batch_size=batch_size,shuffle=False,num_workers=num_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The train set contains {} images, in {} batches\".format(len(train_loader.dataset), len(train_loader)))\n",
    "print(\"The test set contains {} images, in {} batches\".format(len(test_loader.dataset), len(test_loader)))\n",
    "nsamples = 10\n",
    "classes_names = ['0', '1', '2', '3', '4', '5','6', '7', '8', '9']\n",
    "imgs_test, labels = next(iter(test_loader))\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "for i in range(nsamples):\n",
    "    ax = plt.subplot(1,nsamples, i+1)\n",
    "    plt.imshow(imgs_test[i, 0, :, :], vmin=0, vmax=1.0, cmap=matplotlib.cm.gray)\n",
    "    ax.set_title(\"{}\".format(classes_names[labels[i]]), fontsize=15)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, encoder, decoder, encoding_dim):\n",
    "        super(AE, self).__init__()\n",
    "        self.encoding_dims = encoding_dim\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(AE):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, encoding_dims, latent_dims):\n",
    "        super(VAE, self).__init__(encoder, decoder, encoding_dims)\n",
    "        self.latent_dims = latent_dims\n",
    "        self.mu = nn.Sequential(nn.Linear(self.encoding_dims, self.latent_dims))#, nn.ReLU())\n",
    "        self.sigma = nn.Sequential(nn.Linear(self.encoding_dims, self.latent_dims), nn.Softplus())\n",
    "        \n",
    "    def encode(self, x):\n",
    "        z = self.encoder(x)\n",
    "        mu = self.mu(z)\n",
    "        sigma = self.sigma(z)\n",
    "        return mu, sigma\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode the inputs\n",
    "        z_params = self.encode(x)\n",
    "        # Obtain latent samples and latent loss\n",
    "        z_tilde, kl_div = self.latent(x, z_params)\n",
    "        # Decode the samples\n",
    "        x_tilde = self.decode(z_tilde)\n",
    "        return x_tilde.reshape(-1, 1, 28, 28), kl_div\n",
    "    \n",
    "    def latent(self, x, z_params):\n",
    "        mu, sigma = z_params\n",
    "        epsilon = torch.randn_like(sigma)\n",
    "        z = mu + sigma * epsilon\n",
    "        kl_div = (1/2) * (torch.sum(1 + torch.log(sigma ** 2) - (mu ** 2) - (sigma ** 2)))        \n",
    "        return z, kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(torch.nn.Module):\n",
    "    def __init__(self, outer_shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.outer_shape = outer_shape\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), *self.outer_shape)\n",
    "\n",
    "def construct_encoder_decoder_complex(nin, n_latent = 16, n_hidden = 512, n_params = 0, n_classes = 1):\n",
    "    \n",
    "    \n",
    "    # Encoder network\n",
    "    encoder = nn.Sequential(\n",
    "        nn.Conv2d(nin, out_channels= 64, kernel_size= 3),\n",
    "        nn.ReLU(),\n",
    "        # nn.MaxPool2d(2, 2),\n",
    "        nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size= 3),\n",
    "        nn.ReLU(),\n",
    "        # nn.MaxPool2d(2, 2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(128*24*24, n_hidden), nn.ReLU(),\n",
    "        nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "        nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "    )\n",
    "\n",
    "    # Decoder network\n",
    "    decoder = nn.Sequential(\n",
    "        nn.Linear(n_latent, n_hidden), nn.ReLU(),\n",
    "        nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "        nn.Linear(n_hidden, 128*24*24), nn.ReLU(),\n",
    "        Reshape((128,24,24)),\n",
    "        nn.ConvTranspose2d(128,64,3),nn.ReLU(),\n",
    "        nn.ConvTranspose2d(64,nin * n_classes,3),nn.ReLU(),\n",
    "    )\n",
    "\n",
    "   # decoder = nn.Sequential(decoder1,decoder2)\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_encoder_decoder(nin, n_latent = 16, n_hidden = 512, n_classes = 1):\n",
    "    # Encoder network\n",
    "    encoder = nn.Sequential(\n",
    "          nn.Flatten(),\n",
    "          nn.Linear(nin, n_hidden), nn.ReLU(),\n",
    "          nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "          nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "    )\n",
    "    # Decoder network\n",
    "    decoder = nn.Sequential(\n",
    "          nn.Linear(n_latent, n_hidden), nn.ReLU(),\n",
    "          nn.Linear(n_hidden, n_hidden), nn.ReLU(),\n",
    "          nn.Linear(n_hidden, nin * n_classes), nn.Sigmoid()\n",
    "    )\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction criterion\n",
    "recons_criterion = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "def compute_loss(model, x):\n",
    "    beta = 1.5\n",
    "    z_params = model.encode(x)\n",
    "    z, DKL = model.latent(x,z_params)\n",
    "    x_predis = model.decode(z)\n",
    "    loss = torch.sum(recons_criterion(x,x_predis.reshape(-1, 1, 28, 28)))\n",
    "    full_loss = - beta * DKL + loss\n",
    "    return full_loss, DKL, loss\n",
    "\n",
    "def train_step(model, x, optimizer):\n",
    "    # Compute the loss.\n",
    "    loss, kld, loss_tot = compute_loss(model, x)\n",
    "    # Before the backward pass,£ zero all of the network gradients\n",
    "    optimizer.zero_grad()\n",
    "    # Backward pass: compute gradient of the loss with respect to parameters\n",
    "    loss.backward()\n",
    "    # Calling the step function to update the parameters\n",
    "    optimizer.step()\n",
    "    return loss, kld, loss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Bernoulli or Multinomial loss\n",
    "num_classes = 1\n",
    "# Number of hidden and latent\n",
    "n_hidden = 512\n",
    "n_latent = 2\n",
    "# Compute input dimensionality\n",
    "nin = 1 #:pour le complex #pour le normalimgs_test.shape[2] * imgs_test.shape[3]\n",
    "# Construct encoder and decoder\n",
    "encoder, decoder = construct_encoder_decoder_complex(nin, n_hidden = n_hidden, n_latent = n_latent, n_classes = num_classes)\n",
    "# Build the VAE model\n",
    "model = VAE(encoder, decoder, n_hidden, n_latent)\n",
    "# Construct the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('Resultat_VAE_chiffre/essai_convolutionnel_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_sample):\n",
    "    predictions, _ = model(test_sample)\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(predictions[i, 0, :, :].detach(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    # Tight_layout minimizes the overlap between 2 sub-plots\n",
    "    #plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "    plt.close()\n",
    "    return(fig)\n",
    "\n",
    "epochs = 50\n",
    "losses_kld = []\n",
    "test_sample = imgs_test[0:16, :, :, :]\n",
    "for epoch in range(1, epochs + 1):\n",
    "\n",
    "    full_loss = torch.Tensor([0])\n",
    "    kld = torch.Tensor([0])\n",
    "    loss = torch.Tensor([0])\n",
    "    # Forward pass: compute predicted y by passing x to the model.\n",
    "    for i, (x, _) in enumerate(train_loader):\n",
    "        full_loss_b, kld_b, loss_b= train_step(model, x, optimizer)\n",
    "        full_loss += full_loss_b\n",
    "        kld += kld_b\n",
    "        loss += loss_b\n",
    "    #for i, (x, _) in enumerate(valid_loader):\n",
    "    #    train_step(model, x, optimizer)\n",
    "    losses_kld.append(full_loss.detach().numpy())\n",
    "    #print('Epoch: {}, Test set ELBO: {}'.format(epoch, full_loss))\n",
    "    fig = generate_and_save_images(model, epoch, test_sample)\n",
    "\n",
    "    \n",
    "    writer.add_scalar('Loss/Loss_total',full_loss,epoch)\n",
    "    writer.add_scalar('Loss/kld',kld,epoch)\n",
    "    writer.add_scalar('Loss/loss',loss,epoch)\n",
    "    writer.add_figure('washionMist_evolv',fig,epoch)\n",
    "    writer.flush()\n",
    "\n",
    "##metttre KL et losses dans writer\n",
    "\n",
    "##ajouter writer.add_mbeding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## en théorie y a que des trucs entre genre -3 et 3 (dans le range d'une gaussienne)\n",
    "\n",
    "x = np.linspace(-3, 3, 20)\n",
    "y = np.linspace(-3, 3, 20)\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "for i in range(20):\n",
    "    for j in range(20):\n",
    "        plt.subplot(20, 20, (i * 20) + j + 1)\n",
    "        final_tensor = torch.zeros(2)\n",
    "        final_tensor[0] = x[i]\n",
    "        final_tensor[1] = y[j]\n",
    "        plt.imshow(model.decode(final_tensor).detach().reshape(28, 28), cmap='gray')\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k(x,y,var):\n",
    "    return(torch.exp(- abs(x - y)**2 / 2 / torch.std(x,y) ** 2))\n",
    "\n",
    "def compute_mmd(x, y):\n",
    "\n",
    "    MMD = torch.mean(k(x,x)) + torch.mean(k(y,y)) - 2 * torch.mean(k(x,y))\n",
    "    return(MMD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
